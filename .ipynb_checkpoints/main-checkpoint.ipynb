{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias', 'features.5.weight', 'features.5.bias', 'features.7.weight', 'features.7.bias', 'features.10.weight', 'features.10.bias', 'features.12.weight', 'features.12.bias', 'features.14.weight', 'features.14.bias', 'features.17.weight', 'features.17.bias', 'features.19.weight', 'features.19.bias', 'features.21.weight', 'features.21.bias', 'features.24.weight', 'features.24.bias', 'features.26.weight', 'features.26.bias', 'features.28.weight', 'features.28.bias', 'classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias', 'classifier.6.weight', 'classifier.6.bias'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = vgg.state_dict()\n",
    "features_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight \t torch.Size([64, 3, 3, 3])\n",
      "features.0.bias \t torch.Size([64])\n",
      "features.2.weight \t torch.Size([64, 64, 3, 3])\n",
      "features.2.bias \t torch.Size([64])\n",
      "features.5.weight \t torch.Size([128, 64, 3, 3])\n",
      "features.5.bias \t torch.Size([128])\n",
      "features.7.weight \t torch.Size([128, 128, 3, 3])\n",
      "features.7.bias \t torch.Size([128])\n",
      "features.10.weight \t torch.Size([256, 128, 3, 3])\n",
      "features.10.bias \t torch.Size([256])\n",
      "features.12.weight \t torch.Size([256, 256, 3, 3])\n",
      "features.12.bias \t torch.Size([256])\n",
      "features.14.weight \t torch.Size([256, 256, 3, 3])\n",
      "features.14.bias \t torch.Size([256])\n",
      "features.17.weight \t torch.Size([512, 256, 3, 3])\n",
      "features.17.bias \t torch.Size([512])\n",
      "features.19.weight \t torch.Size([512, 512, 3, 3])\n",
      "features.19.bias \t torch.Size([512])\n",
      "features.21.weight \t torch.Size([512, 512, 3, 3])\n",
      "features.21.bias \t torch.Size([512])\n",
      "features.24.weight \t torch.Size([512, 512, 3, 3])\n",
      "features.24.bias \t torch.Size([512])\n",
      "features.26.weight \t torch.Size([512, 512, 3, 3])\n",
      "features.26.bias \t torch.Size([512])\n",
      "features.28.weight \t torch.Size([512, 512, 3, 3])\n",
      "features.28.bias \t torch.Size([512])\n",
      "classifier.0.weight \t torch.Size([4096, 25088])\n",
      "classifier.0.bias \t torch.Size([4096])\n",
      "classifier.3.weight \t torch.Size([4096, 4096])\n",
      "classifier.3.bias \t torch.Size([4096])\n",
      "classifier.6.weight \t torch.Size([1000, 4096])\n",
      "classifier.6.bias \t torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "layer_mapping = {}\n",
    "for i,param_tensor in enumerate(features_dict):\n",
    "    if i&1 == 0:\n",
    "        layer_mapping[i//2] = [param_tensor]\n",
    "    else:\n",
    "        layer_mapping[i//2].append(param_tensor)\n",
    "    print(param_tensor, \"\\t\", features_dict[param_tensor].size()) #get feature summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['features.0.weight', 'features.0.bias'],\n",
       " 1: ['features.2.weight', 'features.2.bias'],\n",
       " 2: ['features.5.weight', 'features.5.bias'],\n",
       " 3: ['features.7.weight', 'features.7.bias'],\n",
       " 4: ['features.10.weight', 'features.10.bias'],\n",
       " 5: ['features.12.weight', 'features.12.bias'],\n",
       " 6: ['features.14.weight', 'features.14.bias'],\n",
       " 7: ['features.17.weight', 'features.17.bias'],\n",
       " 8: ['features.19.weight', 'features.19.bias'],\n",
       " 9: ['features.21.weight', 'features.21.bias'],\n",
       " 10: ['features.24.weight', 'features.24.bias'],\n",
       " 11: ['features.26.weight', 'features.26.bias'],\n",
       " 12: ['features.28.weight', 'features.28.bias']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discard classifier layer\n",
    "for i in range(13,16):\n",
    "    del layer_mapping[i]\n",
    "    \n",
    "layer_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        #initialize layers\n",
    "        \n",
    "        #Layer 0\n",
    "        self.Layer_0 = nn.Conv2d(3,64,3)\n",
    "        Layer_0.weight.data.fill_(features_dict[layer_mapping[0][0]])\n",
    "        Layer_0.bias.data.fill_(features_dict[layer_mapping[0][1]])\n",
    "        \n",
    "        #Layer 1\n",
    "        self.Layer_1 = nn.Conv2d(64,64,3)\n",
    "        Layer_1.weight.data.fill_(features_dict[layer_mapping[1][0]])\n",
    "        Layer_1.bias.data.fill_(features_dict[layer_mapping[1][1]])\n",
    "\n",
    "        #Layer 2\n",
    "        self.Layer_2 = nn.Conv2d(64,128,3)\n",
    "        Layer_2.weight.data.fill_(features_dict[layer_mapping[2][0]])\n",
    "        Layer_2.bias.data.fill_(features_dict[layer_mapping[2][1]])\n",
    "        \n",
    "        #Layer 3\n",
    "        self.Layer_3 = nn.Conv2d(128,128,3)\n",
    "        Layer_3.weight.data.fill_(features_dict[layer_mapping[3][0]])\n",
    "        Layer_3.bias.data.fill_(features_dict[layer_mapping[3][1]])\n",
    "        \n",
    "        #Layer 4\n",
    "        self.Layer_4 = nn.Conv2d(128,256,3)\n",
    "        Layer_4.weight.data.fill_(features_dict[layer_mapping[4][0]])\n",
    "        Layer_4.bias.data.fill_(features_dict[layer_mapping[4][1]])\n",
    "        \n",
    "        #Layer 5\n",
    "        self.Layer_5 = nn.Conv2d(256,256,3)\n",
    "        Layer_5.weight.data.fill_(features_dict[layer_mapping[5][0]])\n",
    "        Layer_5.bias.data.fill_(features_dict[layer_mapping[5][1]])\n",
    "        \n",
    "        #Layer 6\n",
    "        self.Layer_6 = nn.Conv2d(256,256,3)\n",
    "        Layer_6.weight.data.fill_(features_dict[layer_mapping[6][0]])\n",
    "        Layer_6.bias.data.fill_(features_dict[layer_mapping[6][1]])\n",
    "        \n",
    "        #Layer 7\n",
    "        self.Layer_7 = nn.Conv2d(256,512,3)\n",
    "        Layer_7.weight.data.fill_(features_dict[layer_mapping[7][0]])\n",
    "        Layer_7.bias.data.fill_(features_dict[layer_mapping[7][1]])\n",
    "        \n",
    "        #Layer 8\n",
    "        self.Layer_8 = nn.Conv2d(512,512,3)\n",
    "        Layer_8.weight.data.fill_(features_dict[layer_mapping[8][0]])\n",
    "        Layer_8.bias.data.fill_(features_dict[layer_mapping[8][1]])\n",
    "        \n",
    "        #Layer 9\n",
    "        self.Layer_9 = nn.Conv2d(512,512,3)\n",
    "        Layer_9.weight.data.fill_(features_dict[layer_mapping[9][0]])\n",
    "        Layer_9.bias.data.fill_(features_dict[layer_mapping[9][1]])\n",
    "        \n",
    "        #Layer 10\n",
    "        self.Layer_10 = nn.Conv2d(512,512,3)\n",
    "        Layer_10.weight.data.fill_(features_dict[layer_mapping[10][0]])\n",
    "        Layer_10.bias.data.fill_(features_dict[layer_mapping[10][1]])\n",
    "        \n",
    "        #Layer 11\n",
    "        self.Layer_11 = nn.Conv2d(512,512,3)\n",
    "        Layer_11.weight.data.fill_(features_dict[layer_mapping[11][0]])\n",
    "        Layer_11.bias.data.fill_(features_dict[layer_mapping[11][1]])\n",
    "        \n",
    "        #Layer 12\n",
    "        self.Layer_12 = nn.Conv2d(512,512,3)\n",
    "        Layer_12.weight.data.fill_(features_dict[layer_mapping[12][0]])\n",
    "        Layer_12.bias.data.fill_(features_dict[layer_mapping[12][1]])\n",
    "        \n",
    "    def forward(self, x, layer):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
